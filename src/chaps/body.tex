\chapter{Introduction}

\chapter{Methodology}
\input{chaps/methodology.tex}

\chapter{Artificial Intelligence}

% TODO intro from russel book summarized 
\section{Learning}

% TODO intro from russel chapter learning 
\subsection{Supervised Learning}
\input{chaps/supervisedlearning.tex}
\subsection{Unsupervised Learning}
\section{Neural Networks}
\section{Backpropagation}

\chapter{Reinforcement Learning}
\section{Policy Search}
\section{Deep Reinforcement Learning}

%TODO paper deep \ac{RL} > mixing R.L and deep \ac{NN} 
\section{Proximal Policy Optimization OR(TBD) Deep Q learning}

\chapter{Animal Cognition}
\section{Recognition}
\section{Memory}
\section{Social Cognition}

\chapter{Competitive Simulations}%as a tool of experimental research into AI

\chapter{Power Trading Agent Competition}
\input{chaps/powertac.tex}

\chapter{Implementation}
\input{chaps/implementation.tex}

\chapter{Results}
\chapter{Conclusion}



%\section{Imitating locomotion in the OpenAI Gym}
%\subsection{Training a normal PPO agent}
%\subsection{Letting agents observe each others movements}







\chapter{Results}

\chapter{Conclusion}
